{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from data.image_folder_dataset import ImageFolderDataset\n",
    "from processing.XDoG import xdog\n",
    "from processing.transforms import RandomSketch, Sketch\n",
    "from data.image_data_module import ImageDataModule\n",
    "from networks.modules import SketchColoringModule, PaintCorrectionModule\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities.model_summary import _format_summary_table, summarize\n",
    "\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some variables\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "DATASET_PATH = 'portraits/'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = ImageDataModule(data_dir=DATASET_PATH, batch_size=4, image_size=256, hatch_pattern_path=\"./processing/textures/\")\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining network hpyeprapameters here. Hyperparameters can include anything and will be saved in model checkpoints\n",
    "# These hyperparameters will be avaialable in the neural network module.\n",
    "\n",
    "# UNet encoder and decoder dimensions\n",
    "# !!! Output and bottleneck are automatically added in the code.\n",
    "colorizer_params = {\n",
    "  'encoder_blocks': [\n",
    "    {'in_c': 1, 'out_c': 32, 'normalize': False, 'affine': False, 'p': 0.5},\n",
    "    {'in_c': 32, 'out_c': 64, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 64, 'out_c': 128, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 128, 'out_c': 256, 'normalize': True, 'affine': False, 'p': 0},\n",
    "  ],\n",
    "  'decoder_blocks': [\n",
    "    {'in_c': 512, 'out_c': 256, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 256, 'out_c': 128, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 128, 'out_c': 64, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 64, 'out_c': 32, 'normalize': True, 'affine': False, 'p': 0},\n",
    "  ],\n",
    "  'activation': 'sigmoid'\n",
    "}\n",
    "\n",
    "style_params = {\n",
    "  'encoder_blocks': [\n",
    "    {'in_c': 3, 'out_c': 32, 'normalize': False, 'affine': False, 'p': 0},\n",
    "    {'in_c': 32, 'out_c': 64, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 64, 'out_c': 128, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 128, 'out_c': 256, 'normalize': True, 'affine': False, 'p': 0},\n",
    "  ],\n",
    "}\n",
    "\n",
    "discriminator_params = {\n",
    "  'encoder_blocks': [\n",
    "    {'in_c': 4, 'out_c': 32, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 32, 'out_c': 64, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 64, 'out_c': 128, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 128, 'out_c': 256, 'normalize': True, 'affine': False, 'p': 0},\n",
    "    {'in_c': 256, 'out_c': 512, 'normalize': True, 'affine': False, 'p': 0},\n",
    "  ],\n",
    "}\n",
    "\n",
    "hparams = {\n",
    "  \"colorizer_params\": colorizer_params,\n",
    "  \"discriminator_params\": discriminator_params,\n",
    "  \"style_params\": style_params,\n",
    "  \"num_exemplars\": 1,\n",
    "  \"exemplar_method\": \"self\",\n",
    "  \"train_gan\": True,\n",
    "  \"generator_frequency\": 1,\n",
    "  \"discriminator_frequency\": 1,\n",
    "  \"g\": 1,\n",
    "  \"rec\": 0,\n",
    "  \"perc\": 0,\n",
    "  \"color\": 100,\n",
    "  \"l1_beta\": 0.1,\n",
    "  \"colorizer_lr\": 1e-4,\n",
    "  \"min_lr\": 1e-3,\n",
    "  \"max_lr\": 1e-2,\n",
    "  \"discriminator_lr\": 4e-4,\n",
    "  \"b1\": 0.5,\n",
    "  \"b2\": 0.99,\n",
    "  \"disc_b1\": 0,\n",
    "  \"disc_b2\": 0,\n",
    "  \"weight_decay\": 1e-5,\n",
    "  \"perceptual_layer\": [17],\n",
    "  \"gan_loss\": 'BCE',\n",
    "  \"texture\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SketchColoringModule(device=device, **hparams).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard to view visualisations realtime during training\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Pytorch Lightning provides a Trainer class which handles training loop.\n",
    "The trainer automatically performs validation and training steps while also\n",
    "logging key metrics which enables effective training.\n",
    "\n",
    "The trainer takes in data modules and a model and automatically sets up the training loop\n",
    "\n",
    "\n",
    "The trainier automatically handles GPU or TPU training without the need of\n",
    "manually casting tensors to device.\n",
    "\n",
    "The trainer saves model checkpoints so that best models can later be recovered\n",
    "\n",
    "The trainer supports wide variety of options which make model training more efficient\n",
    "and fast (16 bit precision, debugging, early stopping, etc.)\n",
    "\n",
    "Full manual can be found here: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html\n",
    "'''\n",
    "# Getting a warning about ambigous batch size\n",
    "# The warning is nothing serious, it happens because pytorch lightning\n",
    "# does not handle dictionaries as data inputs well. In reality training loop\n",
    "# works properly\n",
    "\n",
    "# Warning: https://github.com/PyTorchLightning/pytorch-lightning/issues/10349 \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "classifier_logger = TensorBoardLogger(save_dir='lightning_logs', log_graph = False)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  monitor=\"val_loss\",\n",
    "  dirpath=\"models/\",\n",
    "  filename=\"colorizer\",\n",
    "  save_top_k=1,\n",
    "  mode=\"min\",\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "  overfit_batches=2, # debug option, overfits the given proportion of the whole data\n",
    "  track_grad_norm=2, # debug option, tracks gradient norms in tensorboard\n",
    "  default_root_dir=os.getcwd(), # The directory to save and log training results\n",
    "  max_epochs=500,\n",
    "  gpus=1 if torch.cuda.is_available() else None, # Uncomment to use GPU training when available\n",
    "  val_check_interval=0.1, # validate 10 times per epoch, frequent validation is helpful\n",
    "  logger=classifier_logger, # Logger options to track training\n",
    "  callbacks=[checkpoint_callback],\n",
    "  gradient_clip_val = 1.0,\n",
    "  gradient_clip_algorithm=\"value\",\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31967d5c181c7ff85d37b6d2b47d9b9abe3f7c0ca0eef40ff8acd5edd0780815"
  },
  "kernelspec": {
   "display_name": "Venv Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
